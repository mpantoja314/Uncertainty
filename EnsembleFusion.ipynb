{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCXhKy0gE2-f"
      },
      "outputs": [],
      "source": [
        "#%%writefile digitsFusion.py\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "#from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "#from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Average\n",
        "from keras.layers import Lambda\n",
        "from tensorflow.keras import optimizers\n",
        "from keras import backend as K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EZ6McLK5TsL"
      },
      "outputs": [],
      "source": [
        "#hyperparameter values\n",
        "learningrate=0.01\n",
        "momentum=0.1\n",
        "epochs=100\n",
        "input_shape = (28, 28, 1)\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "#  to split the data of training and testing sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#Data Preprocessing\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# conversion of class vectors to matrices of  binary class\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq8IRTu0FnXh"
      },
      "outputs": [],
      "source": [
        "#https://www.educative.io/answers/how-to-merge-two-different-models-in-keras\n",
        "#https://stackoverflow.com/questions/61059918/could-not-compute-output-tensor-error-in-keras-functional-api\n",
        "\n",
        "# add a layer that returns the concatenation\n",
        "# of the positive part of the input and\n",
        "# the opposite of the negative part\n",
        "\n",
        "def Std_Dev(v):\n",
        "    a=1/3*((v[0]-v[3])^2+(v[1]-v[3])^2+(v[2]-v[3])^2)\n",
        "    return a\n",
        "\n",
        "#create model A\n",
        "#model = Sequential()\n",
        "#we don't want a sequential model\n",
        "a_in = Input(shape=input_shape, name=\"Input_a\")\n",
        "modelA1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"a_layer_1\")(a_in)\n",
        "modelA2=Conv2D(64, (3, 3), activation='relu',name =\"a_layer_2\")(modelA1)\n",
        "modelA3=MaxPooling2D(pool_size=(2, 2),name =\"a_layer_3\")(modelA2)\n",
        "modelA4=Dropout(0.25,name =\"a_layer_4\")(modelA3)\n",
        "modelA5=Flatten(name =\"a_layer_5\")(modelA4)\n",
        "a_out= Dense(num_classes, activation='softmax',name =\"a_out\")(modelA5)\n",
        "#a_out= Dense(num_classes, activation='relu',name =\"a_out\")(modelA5)\n",
        "\n",
        "\n",
        "#create model B\n",
        "b_in = Input(shape=input_shape, name=\"Input_b\")\n",
        "modelB1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"b_layer_1\")(b_in)\n",
        "modelB2=Conv2D(64, (3, 3), activation='relu',name =\"b_layer_2\")(modelB1)\n",
        "modelB3=MaxPooling2D(pool_size=(2, 2),name =\"b_layer_3\")(modelB2)\n",
        "modelB4=Dropout(0.25,name =\"b_layer_4\")(modelB3)\n",
        "modelB5=Flatten(name =\"b_layer_5\")(modelB4)\n",
        "b_out= Dense(num_classes, activation='softmax',name =\"b_out\")(modelB5)\n",
        "#b_out= Dense(num_classes, activation='relu',name =\"b_out\")(modelB5)\n",
        "\n",
        "#create model C\n",
        "c_in = Input(shape=input_shape, name=\"Input_c\")\n",
        "modelC1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"c_layer_1\")(c_in)\n",
        "modelC2=Conv2D(64, (3, 3), activation='relu',name =\"c_layer_2\")(modelC1)\n",
        "modelC3=MaxPooling2D(pool_size=(2, 2),name =\"c_layer_3\")(modelC2)\n",
        "modelC4=Dropout(0.25,name =\"c_layer_4\")(modelC3)\n",
        "modelC5=Flatten(name =\"c_layer_5\")(modelC4)\n",
        "c_out= Dense(num_classes, activation='softmax',name =\"c_out\")(modelC5)\n",
        "#c_out= Dense(num_classes, activation='relu',name =\"c_out\")(modelC5)\n",
        "\n",
        "#create model D\n",
        "d_in = Input(shape=input_shape, name=\"Input_d\")\n",
        "modelD1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"d_layer_1\")(d_in)\n",
        "modelD2=Conv2D(64, (3, 3), activation='relu',name =\"d_layer_2\")(modelD1)\n",
        "modelD3=MaxPooling2D(pool_size=(2, 2),name =\"d_layer_3\")(modelD2)\n",
        "modelD4=Dropout(0.25,name =\"d_layer_4\")(modelD3)\n",
        "modelD5=Flatten(name =\"d_layer_5\")(modelD4)\n",
        "d_out= Dense(num_classes, activation='softmax',name =\"d_out\")(modelD5)\n",
        "#c_out= Dense(num_classes, activation='relu',name =\"c_out\")(modelC5)#create model D\n",
        "\n",
        "e_in = Input(shape=input_shape, name=\"Input_e\")\n",
        "modelE1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"e_layer_1\")(e_in)\n",
        "modelE2=Conv2D(64, (3, 3), activation='relu',name =\"e_layer_2\")(modelE1)\n",
        "modelE3=MaxPooling2D(pool_size=(2, 2),name =\"e_layer_3\")(modelE2)\n",
        "modelE4=Dropout(0.25,name =\"e_layer_4\")(modelE3)\n",
        "modelE5=Flatten(name =\"e_layer_5\")(modelE4)\n",
        "e_out= Dense(num_classes, activation='softmax',name =\"e_out\")(modelE5)\n",
        "#c_out= Dense(num_classes, activation='relu',name =\"c_out\")(modelC5)#create model C\n",
        "\n",
        "f_in = Input(shape=input_shape, name=\"Input_f\")\n",
        "modelF1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"f_layer_1\")(f_in)\n",
        "modelF2=Conv2D(64, (3, 3), activation='relu',name =\"f_layer_2\")(modelF1)\n",
        "modelF3=MaxPooling2D(pool_size=(2, 2),name =\"f_layer_3\")(modelF2)\n",
        "modelF4=Dropout(0.25,name =\"f_layer_4\")(modelF3)\n",
        "modelF5=Flatten(name =\"f_layer_5\")(modelF4)\n",
        "f_out= Dense(num_classes, activation='softmax',name =\"f_out\")(modelF5)\n",
        "#c_out= Dense(num_classes, activation='relu',name =\"c_out\")(modelC5)#create model C\n",
        "\n",
        "g_in = Input(shape=input_shape, name=\"Input_g\")\n",
        "modelG1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"g_layer_1\")(g_in)\n",
        "modelG2=Conv2D(64, (3, 3), activation='relu',name =\"g_layer_2\")(modelG1)\n",
        "modelG3=MaxPooling2D(pool_size=(2, 2),name =\"g_layer_3\")(modelG2)\n",
        "modelG4=Dropout(0.25,name =\"g_layer_4\")(modelG3)\n",
        "modelG5=Flatten(name =\"g_layer_5\")(modelG4)\n",
        "g_out= Dense(num_classes, activation='softmax',name =\"g_out\")(modelG5)\n",
        "#c_out= Dense(num_classes, activation='relu',name =\"c_out\")(modelC5)#create model C\n",
        "\n",
        "h_in = Input(shape=input_shape, name=\"Input_h\")\n",
        "modelH1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"h_layer_1\")(h_in)\n",
        "modelH2=Conv2D(64, (3, 3), activation='relu',name =\"h_layer_2\")(modelH1)\n",
        "modelH3=MaxPooling2D(pool_size=(2, 2),name =\"h_layer_3\")(modelH2)\n",
        "modelH4=Dropout(0.25,name =\"h_layer_4\")(modelH3)\n",
        "modelH5=Flatten(name =\"h_layer_5\")(modelH4)\n",
        "h_out= Dense(num_classes, activation='softmax',name =\"h_out\")(modelH5)\n",
        "#c_out= Dense(num_classes, activation='relu',name =\"c_out\")(modelC5)#create model C\n",
        "\n",
        "i_in = Input(shape=input_shape, name=\"Input_i\")\n",
        "modelI1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"i_layer_1\")(i_in)\n",
        "modelI2=Conv2D(64, (3, 3), activation='relu',name =\"i_layer_2\")(modelI1)\n",
        "modelI3=MaxPooling2D(pool_size=(2, 2),name =\"i_layer_3\")(modelI2)\n",
        "modelI4=Dropout(0.25,name =\"i_layer_4\")(modelI3)\n",
        "modelI5=Flatten(name =\"i_layer_5\")(modelI4)\n",
        "i_out= Dense(num_classes, activation='softmax',name =\"i_out\")(modelI5)\n",
        "#c_out= Dense(num_classes, activation='relu',name =\"c_out\")(modelC5)#create model C\n",
        "\n",
        "j_in = Input(shape=input_shape, name=\"Input_j\")\n",
        "modelJ1=Conv2D(32, kernel_size=(3, 3),activation='relu',name=\"j_layer_1\")(j_in)\n",
        "modelJ2=Conv2D(64, (3, 3), activation='relu',name =\"j_layer_2\")(modelJ1)\n",
        "modelJ3=MaxPooling2D(pool_size=(2, 2),name =\"j_layer_3\")(modelJ2)\n",
        "modelJ4=Dropout(0.25,name =\"j_layer_4\")(modelJ3)\n",
        "modelJ5=Flatten(name =\"j_layer_5\")(modelJ4)\n",
        "j_out= Dense(num_classes, activation='softmax',name =\"j_out\")(modelJ5)\n",
        "#c_out= Dense(num_classes, activation='relu',name =\"c_out\")(modelC5)#create model C\n",
        "\n",
        "\n",
        "#Merging modela\n",
        "a_b = concatenate([a_out,b_out,c_out,d_out,e_out,f_out,g_out,h_out,i_out,j_out],name=\"concatenated_layer\")\n",
        "out = Dense(num_classes, activation='softmax',name =\"out_layer\")(a_b) #this one outputs the softmax\n",
        "out1=Average()([a_out, b_out, c_out,d_out,e_out,f_out,g_out,h_out,i_out,j_out ])\n",
        "#To add more outputs we need to modify the dataset and add two columns the ave and str_dv.\n",
        "#The average should be the same as the label value (SO NO NEED TO ADD TO DATASET) and the std dev Should be 0)\n",
        "#Maybe instead of adding this layer just calculate the std on the prediction so we provide the output of the concatenate layer\n",
        "#https://gist.github.com/akshaychawla/02849170e190fbd7fa9d431450e8d6ef ==Lambda with thee inputs\n",
        "#out2=Lambda(Std_Dev)([a_out,b_out,c_out,out1]) #<-needs to create this one with a lambda function\n",
        "\n",
        "\n",
        "#Model Definition\n",
        "new_combined = Model(inputs=[a_in,b_in,c_in,d_in,e_in,f_in,g_in,h_in,i_in,j_in],outputs=[out,out1], name = \"merged_model\") # Use d_in, e_in, etc. here\n",
        "\n",
        "#new_combined.summary()\n",
        "#keras.utils.plot_model(new_combined, \"architecture_combined.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnwJInAEFrLd"
      },
      "outputs": [],
      "source": [
        "new_combined.compile(loss=keras.losses.categorical_crossentropy,\n",
        "      optimizer='adam',\n",
        "      metrics=[['accuracy'],['accuracy']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrB63j7T8h3a",
        "outputId": "8b380e78-16c3-400b-e81b-74f549bbe771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 71ms/step - average_2_accuracy: 0.8504 - loss: 1.7423 - out_layer_accuracy: 0.8150 - val_average_2_accuracy: 0.9747 - val_loss: 0.3711 - val_out_layer_accuracy: 0.9750\n",
            "Epoch 2/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 50ms/step - average_2_accuracy: 0.9770 - loss: 0.3029 - out_layer_accuracy: 0.9786 - val_average_2_accuracy: 0.9825 - val_loss: 0.1893 - val_out_layer_accuracy: 0.9827\n",
            "Epoch 3/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 50ms/step - average_2_accuracy: 0.9846 - loss: 0.1672 - out_layer_accuracy: 0.9857 - val_average_2_accuracy: 0.9860 - val_loss: 0.1454 - val_out_layer_accuracy: 0.9864\n",
            "Epoch 4/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9869 - loss: 0.1303 - out_layer_accuracy: 0.9880 - val_average_2_accuracy: 0.9860 - val_loss: 0.1282 - val_out_layer_accuracy: 0.9871\n",
            "Epoch 5/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9905 - loss: 0.0921 - out_layer_accuracy: 0.9918 - val_average_2_accuracy: 0.9862 - val_loss: 0.1044 - val_out_layer_accuracy: 0.9865\n",
            "Epoch 6/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9905 - loss: 0.0780 - out_layer_accuracy: 0.9914 - val_average_2_accuracy: 0.9871 - val_loss: 0.0964 - val_out_layer_accuracy: 0.9886\n",
            "Epoch 7/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9926 - loss: 0.0685 - out_layer_accuracy: 0.9935 - val_average_2_accuracy: 0.9881 - val_loss: 0.0995 - val_out_layer_accuracy: 0.9879\n",
            "Epoch 8/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9933 - loss: 0.0578 - out_layer_accuracy: 0.9947 - val_average_2_accuracy: 0.9892 - val_loss: 0.0912 - val_out_layer_accuracy: 0.9895\n",
            "Epoch 9/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9945 - loss: 0.0551 - out_layer_accuracy: 0.9956 - val_average_2_accuracy: 0.9888 - val_loss: 0.0912 - val_out_layer_accuracy: 0.9889\n",
            "Epoch 10/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9957 - loss: 0.0463 - out_layer_accuracy: 0.9966 - val_average_2_accuracy: 0.9886 - val_loss: 0.0930 - val_out_layer_accuracy: 0.9891\n",
            "Epoch 11/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 50ms/step - average_2_accuracy: 0.9953 - loss: 0.0463 - out_layer_accuracy: 0.9963 - val_average_2_accuracy: 0.9889 - val_loss: 0.0910 - val_out_layer_accuracy: 0.9894\n",
            "Epoch 12/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9963 - loss: 0.0419 - out_layer_accuracy: 0.9969 - val_average_2_accuracy: 0.9886 - val_loss: 0.0946 - val_out_layer_accuracy: 0.9875\n",
            "Epoch 13/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9964 - loss: 0.0393 - out_layer_accuracy: 0.9974 - val_average_2_accuracy: 0.9896 - val_loss: 0.0910 - val_out_layer_accuracy: 0.9891\n",
            "Epoch 14/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9967 - loss: 0.0379 - out_layer_accuracy: 0.9976 - val_average_2_accuracy: 0.9892 - val_loss: 0.0947 - val_out_layer_accuracy: 0.9899\n",
            "Epoch 15/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9972 - loss: 0.0348 - out_layer_accuracy: 0.9980 - val_average_2_accuracy: 0.9896 - val_loss: 0.0872 - val_out_layer_accuracy: 0.9901\n",
            "Epoch 16/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9977 - loss: 0.0322 - out_layer_accuracy: 0.9984 - val_average_2_accuracy: 0.9897 - val_loss: 0.0912 - val_out_layer_accuracy: 0.9903\n",
            "Epoch 17/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9971 - loss: 0.0325 - out_layer_accuracy: 0.9981 - val_average_2_accuracy: 0.9899 - val_loss: 0.0904 - val_out_layer_accuracy: 0.9899\n",
            "Epoch 18/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9973 - loss: 0.0313 - out_layer_accuracy: 0.9984 - val_average_2_accuracy: 0.9895 - val_loss: 0.0961 - val_out_layer_accuracy: 0.9895\n",
            "Epoch 19/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9980 - loss: 0.0266 - out_layer_accuracy: 0.9987 - val_average_2_accuracy: 0.9904 - val_loss: 0.0744 - val_out_layer_accuracy: 0.9909\n",
            "Epoch 20/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9979 - loss: 0.0171 - out_layer_accuracy: 0.9989 - val_average_2_accuracy: 0.9904 - val_loss: 0.0782 - val_out_layer_accuracy: 0.9906\n",
            "Epoch 21/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9983 - loss: 0.0157 - out_layer_accuracy: 0.9991 - val_average_2_accuracy: 0.9893 - val_loss: 0.0840 - val_out_layer_accuracy: 0.9896\n",
            "Epoch 22/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9981 - loss: 0.0178 - out_layer_accuracy: 0.9988 - val_average_2_accuracy: 0.9899 - val_loss: 0.0836 - val_out_layer_accuracy: 0.9898\n",
            "Epoch 23/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9979 - loss: 0.0171 - out_layer_accuracy: 0.9988 - val_average_2_accuracy: 0.9902 - val_loss: 0.0813 - val_out_layer_accuracy: 0.9904\n",
            "Epoch 24/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9984 - loss: 0.0132 - out_layer_accuracy: 0.9991 - val_average_2_accuracy: 0.9905 - val_loss: 0.0801 - val_out_layer_accuracy: 0.9902\n",
            "Epoch 25/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9985 - loss: 0.0124 - out_layer_accuracy: 0.9991 - val_average_2_accuracy: 0.9907 - val_loss: 0.0817 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 26/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9982 - loss: 0.0149 - out_layer_accuracy: 0.9988 - val_average_2_accuracy: 0.9888 - val_loss: 0.0926 - val_out_layer_accuracy: 0.9889\n",
            "Epoch 27/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9982 - loss: 0.0154 - out_layer_accuracy: 0.9988 - val_average_2_accuracy: 0.9899 - val_loss: 0.0835 - val_out_layer_accuracy: 0.9903\n",
            "Epoch 28/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9987 - loss: 0.0108 - out_layer_accuracy: 0.9994 - val_average_2_accuracy: 0.9900 - val_loss: 0.0784 - val_out_layer_accuracy: 0.9903\n",
            "Epoch 29/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9985 - loss: 0.0133 - out_layer_accuracy: 0.9991 - val_average_2_accuracy: 0.9909 - val_loss: 0.0836 - val_out_layer_accuracy: 0.9909\n",
            "Epoch 30/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0100 - out_layer_accuracy: 0.9994 - val_average_2_accuracy: 0.9902 - val_loss: 0.0784 - val_out_layer_accuracy: 0.9908\n",
            "Epoch 31/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9986 - loss: 0.0113 - out_layer_accuracy: 0.9993 - val_average_2_accuracy: 0.9908 - val_loss: 0.0835 - val_out_layer_accuracy: 0.9911\n",
            "Epoch 32/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9987 - loss: 0.0103 - out_layer_accuracy: 0.9994 - val_average_2_accuracy: 0.9906 - val_loss: 0.0837 - val_out_layer_accuracy: 0.9911\n",
            "Epoch 33/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0089 - out_layer_accuracy: 0.9994 - val_average_2_accuracy: 0.9914 - val_loss: 0.0839 - val_out_layer_accuracy: 0.9918\n",
            "Epoch 34/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0088 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9909 - val_loss: 0.0806 - val_out_layer_accuracy: 0.9908\n",
            "Epoch 35/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9985 - loss: 0.0132 - out_layer_accuracy: 0.9992 - val_average_2_accuracy: 0.9911 - val_loss: 0.0838 - val_out_layer_accuracy: 0.9914\n",
            "Epoch 36/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9987 - loss: 0.0099 - out_layer_accuracy: 0.9995 - val_average_2_accuracy: 0.9911 - val_loss: 0.0823 - val_out_layer_accuracy: 0.9914\n",
            "Epoch 37/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0089 - out_layer_accuracy: 0.9995 - val_average_2_accuracy: 0.9909 - val_loss: 0.0902 - val_out_layer_accuracy: 0.9910\n",
            "Epoch 38/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9988 - loss: 0.0098 - out_layer_accuracy: 0.9995 - val_average_2_accuracy: 0.9912 - val_loss: 0.0806 - val_out_layer_accuracy: 0.9915\n",
            "Epoch 39/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0073 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9905 - val_loss: 0.0869 - val_out_layer_accuracy: 0.9909\n",
            "Epoch 40/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9987 - loss: 0.0097 - out_layer_accuracy: 0.9994 - val_average_2_accuracy: 0.9910 - val_loss: 0.0800 - val_out_layer_accuracy: 0.9919\n",
            "Epoch 41/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0087 - out_layer_accuracy: 0.9995 - val_average_2_accuracy: 0.9913 - val_loss: 0.0857 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 42/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9991 - loss: 0.0083 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9913 - val_loss: 0.0918 - val_out_layer_accuracy: 0.9916\n",
            "Epoch 43/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0072 - out_layer_accuracy: 0.9996 - val_average_2_accuracy: 0.9918 - val_loss: 0.0878 - val_out_layer_accuracy: 0.9920\n",
            "Epoch 44/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0079 - out_layer_accuracy: 0.9996 - val_average_2_accuracy: 0.9914 - val_loss: 0.0822 - val_out_layer_accuracy: 0.9916\n",
            "Epoch 45/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0088 - out_layer_accuracy: 0.9996 - val_average_2_accuracy: 0.9922 - val_loss: 0.0857 - val_out_layer_accuracy: 0.9923\n",
            "Epoch 46/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0101 - out_layer_accuracy: 0.9995 - val_average_2_accuracy: 0.9908 - val_loss: 0.0875 - val_out_layer_accuracy: 0.9909\n",
            "Epoch 47/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9988 - loss: 0.0085 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9912 - val_loss: 0.0911 - val_out_layer_accuracy: 0.9910\n",
            "Epoch 48/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0075 - out_layer_accuracy: 0.9996 - val_average_2_accuracy: 0.9909 - val_loss: 0.0957 - val_out_layer_accuracy: 0.9911\n",
            "Epoch 49/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9991 - loss: 0.0064 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9907 - val_loss: 0.0928 - val_out_layer_accuracy: 0.9909\n",
            "Epoch 50/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9988 - loss: 0.0073 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9919 - val_loss: 0.0915 - val_out_layer_accuracy: 0.9921\n",
            "Epoch 51/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0061 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9913 - val_loss: 0.0943 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 52/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0067 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9911 - val_loss: 0.0903 - val_out_layer_accuracy: 0.9914\n",
            "Epoch 53/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9988 - loss: 0.0072 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9917 - val_loss: 0.0905 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 54/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0071 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9917 - val_loss: 0.0870 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 55/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0059 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9911 - val_loss: 0.0945 - val_out_layer_accuracy: 0.9905\n",
            "Epoch 56/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9991 - loss: 0.0079 - out_layer_accuracy: 0.9995 - val_average_2_accuracy: 0.9910 - val_loss: 0.0894 - val_out_layer_accuracy: 0.9907\n",
            "Epoch 57/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0068 - out_layer_accuracy: 0.9996 - val_average_2_accuracy: 0.9914 - val_loss: 0.0921 - val_out_layer_accuracy: 0.9915\n",
            "Epoch 58/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0062 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9910 - val_loss: 0.0957 - val_out_layer_accuracy: 0.9909\n",
            "Epoch 59/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0070 - out_layer_accuracy: 0.9995 - val_average_2_accuracy: 0.9911 - val_loss: 0.0925 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 60/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0063 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9908 - val_loss: 0.0906 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 61/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9991 - loss: 0.0066 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9915 - val_loss: 0.0955 - val_out_layer_accuracy: 0.9918\n",
            "Epoch 62/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0062 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9915 - val_loss: 0.0945 - val_out_layer_accuracy: 0.9910\n",
            "Epoch 63/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9991 - loss: 0.0058 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9915 - val_loss: 0.0917 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 64/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0066 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9911 - val_loss: 0.0928 - val_out_layer_accuracy: 0.9905\n",
            "Epoch 65/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9993 - loss: 0.0051 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9912 - val_loss: 0.0960 - val_out_layer_accuracy: 0.9907\n",
            "Epoch 66/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0057 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9919 - val_loss: 0.0923 - val_out_layer_accuracy: 0.9920\n",
            "Epoch 67/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0074 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9914 - val_loss: 0.1004 - val_out_layer_accuracy: 0.9906\n",
            "Epoch 68/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0062 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9917 - val_loss: 0.0940 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 69/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0083 - out_layer_accuracy: 0.9995 - val_average_2_accuracy: 0.9913 - val_loss: 0.1029 - val_out_layer_accuracy: 0.9905\n",
            "Epoch 70/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0068 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9913 - val_loss: 0.0980 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 71/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0049 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9913 - val_loss: 0.0960 - val_out_layer_accuracy: 0.9916\n",
            "Epoch 72/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0056 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9915 - val_loss: 0.0986 - val_out_layer_accuracy: 0.9911\n",
            "Epoch 73/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0056 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9913 - val_loss: 0.0963 - val_out_layer_accuracy: 0.9914\n",
            "Epoch 74/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0054 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9914 - val_loss: 0.0997 - val_out_layer_accuracy: 0.9916\n",
            "Epoch 75/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0057 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9920 - val_loss: 0.0937 - val_out_layer_accuracy: 0.9915\n",
            "Epoch 76/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9994 - loss: 0.0045 - out_layer_accuracy: 0.9999 - val_average_2_accuracy: 0.9916 - val_loss: 0.0986 - val_out_layer_accuracy: 0.9911\n",
            "Epoch 77/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0048 - out_layer_accuracy: 0.9999 - val_average_2_accuracy: 0.9913 - val_loss: 0.0991 - val_out_layer_accuracy: 0.9909\n",
            "Epoch 78/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9993 - loss: 0.0044 - out_layer_accuracy: 0.9999 - val_average_2_accuracy: 0.9920 - val_loss: 0.0971 - val_out_layer_accuracy: 0.9923\n",
            "Epoch 79/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0066 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9915 - val_loss: 0.1046 - val_out_layer_accuracy: 0.9915\n",
            "Epoch 80/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0072 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9921 - val_loss: 0.0989 - val_out_layer_accuracy: 0.9916\n",
            "Epoch 81/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9991 - loss: 0.0064 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9912 - val_loss: 0.1038 - val_out_layer_accuracy: 0.9906\n",
            "Epoch 82/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0067 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9918 - val_loss: 0.0993 - val_out_layer_accuracy: 0.9909\n",
            "Epoch 83/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9991 - loss: 0.0054 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9913 - val_loss: 0.1082 - val_out_layer_accuracy: 0.9908\n",
            "Epoch 84/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9991 - loss: 0.0051 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9909 - val_loss: 0.1050 - val_out_layer_accuracy: 0.9901\n",
            "Epoch 85/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0066 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9916 - val_loss: 0.1103 - val_out_layer_accuracy: 0.9915\n",
            "Epoch 86/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0054 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9907 - val_loss: 0.1069 - val_out_layer_accuracy: 0.9907\n",
            "Epoch 87/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9991 - loss: 0.0065 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9920 - val_loss: 0.1077 - val_out_layer_accuracy: 0.9920\n",
            "Epoch 88/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0055 - out_layer_accuracy: 0.9999 - val_average_2_accuracy: 0.9919 - val_loss: 0.1043 - val_out_layer_accuracy: 0.9917\n",
            "Epoch 89/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9993 - loss: 0.0040 - out_layer_accuracy: 0.9999 - val_average_2_accuracy: 0.9921 - val_loss: 0.1060 - val_out_layer_accuracy: 0.9917\n",
            "Epoch 90/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0045 - out_layer_accuracy: 0.9999 - val_average_2_accuracy: 0.9921 - val_loss: 0.1027 - val_out_layer_accuracy: 0.9919\n",
            "Epoch 91/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0043 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9916 - val_loss: 0.1053 - val_out_layer_accuracy: 0.9915\n",
            "Epoch 92/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9989 - loss: 0.0049 - out_layer_accuracy: 0.9999 - val_average_2_accuracy: 0.9917 - val_loss: 0.1063 - val_out_layer_accuracy: 0.9917\n",
            "Epoch 93/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9994 - loss: 0.0042 - out_layer_accuracy: 0.9999 - val_average_2_accuracy: 0.9919 - val_loss: 0.1065 - val_out_layer_accuracy: 0.9919\n",
            "Epoch 94/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0050 - out_layer_accuracy: 0.9997 - val_average_2_accuracy: 0.9914 - val_loss: 0.1011 - val_out_layer_accuracy: 0.9912\n",
            "Epoch 95/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0051 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9916 - val_loss: 0.1100 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 96/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0048 - out_layer_accuracy: 0.9999 - val_average_2_accuracy: 0.9922 - val_loss: 0.1102 - val_out_layer_accuracy: 0.9919\n",
            "Epoch 97/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9990 - loss: 0.0059 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9919 - val_loss: 0.1046 - val_out_layer_accuracy: 0.9913\n",
            "Epoch 98/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9993 - loss: 0.0040 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9914 - val_loss: 0.1097 - val_out_layer_accuracy: 0.9910\n",
            "Epoch 99/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9993 - loss: 0.0052 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9914 - val_loss: 0.1021 - val_out_layer_accuracy: 0.9912\n",
            "Epoch 100/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - average_2_accuracy: 0.9992 - loss: 0.0052 - out_layer_accuracy: 0.9998 - val_average_2_accuracy: 0.9920 - val_loss: 0.1043 - val_out_layer_accuracy: 0.9910\n",
            "2337.5442640781403\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "#train\n",
        "hist = new_combined.fit(\n",
        "    {'Input_a':x_train, 'Input_b':x_train, 'Input_c':x_train, 'Input_d':x_train, 'Input_e':x_train, 'Input_f':x_train, 'Input_g':x_train, 'Input_h':x_train, 'Input_i':x_train , 'Input_j':x_train},\n",
        "    [y_train,y_train],\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    validation_data=([x_test,x_test,x_test,x_test,x_test,x_test,x_test,x_test,x_test,x_test], [y_test,y_test])\n",
        ")\n",
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdSvRSKq8oNi",
        "outputId": "022a1743-ad7b-45ad-9a6a-839a7189a537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3798 - out_layer_loss: 0.2483 - average_loss: 0.1315 - out_layer_accuracy: 0.9818 - average_accuracy: 0.9829\n",
            "Test loss:  0.37981197237968445\n",
            "Test loss:  0.24827024340629578\n",
            "Test loss:  0.13154169917106628\n",
            "Test Accuracy:  0.9818000197410583\n",
            "[0.37981197237968445, 0.24827024340629578, 0.13154169917106628, 0.9818000197410583, 0.9829000234603882]\n"
          ]
        }
      ],
      "source": [
        "#evaluate\n",
        "score = new_combined.evaluate([x_test,x_test,x_test], [y_test,y_test], verbose=1)\n",
        "print('Test loss: ', score[0])\n",
        "print('Test loss: ', score[1])\n",
        "print('Test loss: ', score[2])\n",
        "print('Test Accuracy: ', score[3])\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4GBiMPKRB7a",
        "outputId": "8a94828b-9fc3-4f68-fa2d-7738dad7cedb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 0.2209 - accuracy: 0.9360 - val_loss: 0.0640 - val_accuracy: 0.9794\n",
            "Epoch 2/2\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0652 - accuracy: 0.9802 - val_loss: 0.0526 - val_accuracy: 0.9822\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0526 - accuracy: 0.9822\n",
            "Test Accuracy:  0.982200026512146\n"
          ]
        }
      ],
      "source": [
        "#One ensamble for testing pourposes same model so should give same results as the fusion\n",
        "#seams fine right now outputs the same accuracy\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from keras import backend as K\n",
        "\n",
        "learningrate=0.01\n",
        "momentum=0.1\n",
        "epochs=2\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "#  to split the data of training and testing sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#Data Preprocessing\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "# conversion of class vectors to matrices of  binary class\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "#create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "#model.add(Dense(256, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#            optimizer=tf.keras.optimizers.SGD(learning_rate=learningrate, momentum=momentum),\n",
        "#            metrics=['accuracy'])\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "      optimizer='adam',\n",
        "      metrics=['accuracy'])\n",
        "#train\n",
        "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "\n",
        "#evaluate\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "#print('Test loss: ', score[0])\n",
        "print('Test Accuracy: ', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yrFckoqMz-i9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}